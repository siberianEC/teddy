# ğŸ§¸ Teddy Bear AI - Speech to Speech con RAG Local

Sistema de IA 100% local para peluches interactivos con capacidades de:
- **Speech-to-Text** con Faster Whisper
- **RAG** (Retrieval Augmented Generation) con ChromaDB
- **LLM** Mistral 7B local
- **Text-to-Speech** para respuestas de voz
- **Baja latencia** y completamente offline

## ğŸš€ CaracterÃ­sticas

- âœ… Procesamiento de voz en tiempo real
- âœ… Memoria conversacional con RAG
- âœ… Respuestas contextuales inteligentes
- âœ… 100% Local (sin internet)
- âœ… Bajo consumo de recursos
- âœ… Latencia optimizada

## ğŸ“‹ Requisitos

- Python 3.9 o superior
- 8GB RAM mÃ­nimo (16GB recomendado)
- 10GB espacio en disco
- MicrÃ³fono funcional

## ğŸ”§ InstalaciÃ³n

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Instalar PyAudio (depende del sistema)

**Linux:**
```bash
sudo apt-get install portaudio19-dev python3-pyaudio
pip install pyaudio
```

**macOS:**
```bash
brew install portaudio
pip install pyaudio
```

**Windows:**
```bash
pip install pipwin
pipwin install pyaudio
```

### 3. Descargar Modelo Mistral 7B

Descarga el modelo desde HuggingFace:

```bash
mkdir models
cd models

# Descargar usando wget o curl
wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf
```

O descarga manualmente desde:
https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF

Guarda como: `./models/mistral-7b-instruct-v0.2.Q4_K_M.gguf`

## ğŸ¯ Uso

```bash
python teddy_bear_ai.py
```

### InteracciÃ³n:
1. Presiona ENTER para comenzar a hablar
2. Habla durante 5 segundos
3. Teddy procesarÃ¡ y responderÃ¡
4. Escribe 'q' + ENTER para salir

## ğŸ—ï¸ Arquitectura

```
Usuario habla â†’ Faster Whisper (STT) â†’ Texto
                                         â†“
                    ChromaDB â† BÃºsqueda de contexto (RAG)
                                         â†“
                    Mistral 7B â†’ Genera respuesta
                                         â†“
                    pyttsx3 (TTS) â†’ Audio respuesta
```

## âš™ï¸ Componentes

### 1. Faster Whisper
- Modelo: `base` (74MB)
- TranscripciÃ³n en espaÃ±ol
- VAD (Voice Activity Detection)
- Latencia: ~1-2 segundos

### 2. Mistral 7B
- CuantizaciÃ³n: Q4_K_M (4.4GB)
- Contexto: 4096 tokens
- Inferencia CPU optimizada
- Latencia: ~2-5 segundos

### 3. RAG con ChromaDB
- Embeddings: all-MiniLM-L6-v2
- Memoria conversacional
- BÃºsqueda semÃ¡ntica
- Persistencia local

### 4. Text-to-Speech
- Motor: pyttsx3
- SÃ­ntesis local
- Latencia mÃ­nima

## ğŸ”Š Ajustes de Latencia

Para reducir latencia:

```python
# En teddy_bear_ai.py, ajusta:

# DuraciÃ³n de grabaciÃ³n (lÃ­nea ~42)
duration=3  # Reducir de 5 a 3 segundos

# Tokens de respuesta (lÃ­nea ~138)
max_tokens=100  # Reducir de 150 a 100

# Modelo Whisper mÃ¡s pequeÃ±o (lÃ­nea ~26)
self.whisper_model = WhisperModel("tiny", ...)  # tiny, base, small
```

## ğŸ“Š Rendimiento Esperado

| Componente | Latencia | RAM |
|------------|----------|-----|
| Whisper (base) | 1-2s | 1GB |
| RAG BÃºsqueda | <0.1s | 500MB |
| Mistral 7B Q4 | 2-5s | 6GB |
| TTS | <0.5s | 100MB |
| **Total** | **4-8s** | **~8GB** |

## ğŸ¨ PersonalizaciÃ³n

### Cambiar personalidad del peluche:

Edita el prompt en `generate_response()`:

```python
prompt = f"""<s>[INST] Eres un [PERSONALIDAD AQUÃ].
Tu nombre es [NOMBRE]. Responde de forma [ESTILO].

Usuario: {user_input}
[/INST]"""
```

### Agregar conocimientos base:

Modifica `init_knowledge_base()`:

```python
knowledge = [
    "Tu nuevo conocimiento aquÃ­",
    "MÃ¡s informaciÃ³n personalizada",
    # ...
]
```

## ğŸ› SoluciÃ³n de Problemas

### Error de micrÃ³fono:
```bash
# Verificar dispositivos de audio
python -c "import sounddevice as sd; print(sd.query_devices())"
```

### Memoria insuficiente:
- Usa modelo Whisper mÃ¡s pequeÃ±o: `tiny`
- Usa Mistral Q3 o Q2 (menor calidad)
- Reduce `n_ctx` a 2048

### TTS no funciona:
```bash
# Linux
sudo apt-get install espeak

# macOS - usa voces del sistema
# Windows - usa SAPI5 automÃ¡tico
```

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto para uso educativo y personal.

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Este peluche puede mejorar con:
- DetecciÃ³n de emociones en voz
- Wake word detection ("Hey Teddy")
- MÃºltiples idiomas
- IntegraciÃ³n con hardware (LEDs, sensores)

## ğŸ”— Enlaces Ãštiles

- [Faster Whisper](https://github.com/guillaumekln/faster-whisper)
- [Llama.cpp](https://github.com/ggerganov/llama.cpp)
- [ChromaDB](https://www.trychroma.com/)
- [Mistral AI](https://mistral.ai/)
